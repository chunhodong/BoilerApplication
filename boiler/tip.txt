1. 데이터유효성 검증로직은Dto에 어노테이션으로처리(이메일형식,비밀번호길이 등등,NOT NULL)
   Entity에는 NOT NULL조건만 추가하여, 비즈니스로직에 의존하지 않게 부여

 - Dto에 검증로직을 부여하여 Dto를 사용하는 컨트롤러나 서비스가 코드중복없이 같은 코드를 사용할수있음
   추가적으로 검증로직을 어노테이션으로 대체한다면 간결하게 유효성 검증이가능
 - 로직을 직접 작성안하고 어노테이션으로 했을때 단점은 검증규칙이 복잡할경우 어노테이션으로 대체하기 힘들수있음
   - 이 경우 커스텀 어노테이션 작성을 고려해볼수있음
   - 커스텀 어노테이션을 안쓴다면 서비스클래스에 검증을 작성해야함
     - 커스텀어노테이션이 너무 많으면 가독성이 떨어질수도있음
   - 좋은방법은 DTO에서는 값자체를 검증하고 로직이 필요한 부분은 서비스클래스에서 작성
     - 예를들어 입력값 양수/음수/NULL/최소길이 등은 DTO에작성, 예를들어 입력했을때 특정필드값이 다른 필드보다 커야한다같은
       로직이 필요한경우는 서비스클래스에 코드로작성 아니면 커스텀어노테이션으로 DTO에 작성


 - Entity에는 필요할경우 검증로직을 추가할수있음 Entity에 검증로직을 추가했을때 장점은 개발자의 실수를
   줄여줄수있음, 만약 새로운 기능을 만들고 상위 레이어에서 유효성검증로직을 실수로 안넣었다면 Entity에서 이를 막아줄수있음
   단점은 Entity책임이 늘어나게되고 Entity가 화면영역에 의존하게됨 단 Entity에 로직이
   자체가 필요없는게 아니라 입력데이터의 유효성검증에 경우를 말함
 - 다만 DB칼럼의 유효성규칙에 해당하는 NOT NULL조건은 추가

 - Service Layer도 위에 Entity처럼 검증로직을 추가할순있지만, Entity에서 추가했을때와 같은 문제발생
   하지만 Service Layer에서 검증로직이 필요한 상황이 존재할수있음, 만약 팀 상황상 서비스레이어만 테스트코드를
   작성해야한다면, 무결성을 위해 Service Layer에도 입력값 검증이 필요할수도있음 이때는 자바에서 제공하는 Validator를 이용하면
   모든DTO에 적용가능한 검증로직작성가능

------------------------------------------------------------------------------------------

 2. 테스트코드

 - TDD를 한다고 했을시 테스트코드성공을위해 프로덕트소스를 고민하는 상황이 발생할수있음
 - 회원의 마지막로그인시간을 갱신하는api개발할때 테스트코드를 작성하지 않는 상황에서 머리속으로 그려본 시나리오는
   회원필드에있는 lastLogin필드를 LocalDateTime.now()로 바꿔주는 메소드를 엔티티에 추가
 - 이 경우 테스트코드를 작성,검증이 상당히번거로움 검증을 위해선 lastLogin필드에있는값이 검증을 위한 입력값하고 똑같아야함
   LocalDateTime.now()는 밀리세컨드 단위까지 나오기때문에 상당히 어려움
 - 해당 케이스는 분단위까지만 검증하는걸로 해결할수 있자만 TDD를하면서 어떻게해야 프로덕트소스를 수정하는걸 생각히자 않고
   기능을 확실하게 검증할수있는지 고민해야함

------------------------------------------------------------------------------------------

3. 예외처리-1
  - 예외는 체크예외 언체크예외 두가지 존재 모든예외는 try-catch로잡거나 throw로 던지거나 둘중하나로 처리해야함
  - 체크예외는 컴파일러가 체크하는 예외, 명시적으로 try-catch로 잡거나 throw를통해서 상위로 던지거나 둘중하나로 처리해야함
  - 언체크예외는 명시적으로 처리하지 않으면 자동으로 상위로 throws함
  - 체크예외는 경우 명시적으로 처리를 해야하기때문에 문제발생가능성 존재
      - 하위계층에서 발생한 예외를 상위계층으로 최상위 계층으로 끝까지 throw를 해버림, 반복적인 코드가 발생
      - 발생하는 예외가 많으질수록 throws에 붙는 예외가 더 늘어나서 코드자체도 복잡해짐
      - throws Exception을통해서 모든예외를 하위에서 throw Exception 해버리면 상위에서는  어떤 예외를 잡았고 어떤 예외를 던지는 알수없음
        더군다나 Exception Advice같은 공통로직에서도 Exception객체로 받기때문에 원인을 파악하기쉽지않음
      - 하위계층에서 예외를 throw해버리고, 상위계층까지 전달됫을때, 이 예외가 특정기술에 종속적인 예외라면, 나머지 계층도 특정기술에 종속적인 코드가 된다.
        - JDBC에서 발생한 SQLException이 컨트롤러까지 도달한상태에서 JDBC를 JPA로 바꾼다면, JDBC에 종속적인 Exception코드를 전부 수정해줘야함
    - 체크예외 문제를 해결하기위한망법을 체크예외를 try-catch한상태에서 언체크드 예외로 감싸서 던지는 방법존재, 언체크드 예외는 명시적으로 기술하지않아도 되기떄문에 코드간 의존관계가
      없고, 반복코드가 필요없음, 언체크드 예외로 던지고 Controller Advice같은 공통처리 로직에서 한번만 처리해주면됨

3.1 예외처리-2
  - 스프링은 컨트롤러 밖으로 예외가 던져지면 예외를 감지해서 동작을 새로 정의할수있는 HandlerExceptionResolver를 제공
  - 스프링부트가 실행되면 HandlerExceptionResolver구현체를 기본적으로 등록
  - HandlerExceptionResolver가 없다면 컨트롤러에서 발생한예외가 WAS까지 전달된후, WAS에서 다시 에러처리를하기위해
    컨트롤러로 에러처리를 요청
  - 기본으로 등록되는 HandlerExceptionResolver구현체중 ExceptionHandlerExceptionResolver는
    @ExceptionHandler어노테이션이붙은 메소드가 예외처리를 함 @ExceptionHandler어노테이션에서 예외를처리하고 응답데이터를
    다시 정의함, 이때 WAS까지 전달된후에 다시 에러처리를 위해 컨트롤러로 요청하지 않고 바로 응답
  - @ExceptionHandler는 컨트롤러에 종속되있기때문에 비즈니스로직과 예외처리 코드가 한 클래스에 존재
  - @ControllerAdvice를 포함한 클래스를 작성하면 @ExceptionHandler메소드만 빼낼수있음
  - @ControllerAdvice를 사용해서 특정 컨트롤러나 특정패키지만 예외처리를 해줄수있음, 없으면 글로벌하게 예외처리

------------------------------------------------------------------------------------------

4. DB
  - mysql
    - mysql의 실행계획은 select_type,table,partitions,type,possible_keys,key,key_len,ref,rows,filtered,Extra 컬럼이 존재
    - 컬럼에 대한 설명은 https://nomadlee.com/mysql-explain-sql/, https://12bme.tistory.com/168
    - 실행계획이 똑같더라도 결과도출속도는 다를 수 있음, 실행계획에서는 추정치를 반환하기도 하기떄문에 더 자세히 볼려면 explain analyze로 검색해야함
    - select_type : SELECT쿼리가 어떤 타입인지 나타내는 용도
      - SIMPLE : 단순 SELECT(Union이나 Sub Query가 없는 SELECT문)

    - table : 어떤 테이블에 대한 정보인지 나타냄

    - partitions : 파티셔닝 테이블일때, 어떤 파티션을 읽었는지 알려줌

    - type : 인덱스 참조에 대한 정보
      - ALL : 테이블을 처음부터 끝까지 검색하는 경우, 일반적으로 테이블 풀스캔이라고함
      - index : 인덱스 테이블을 처음부터 끝까지 검색하는 경우

    - possible_keys : 옵티마이저가 쿼리를 처리하기 위해 여러 처리 방법을 고려하던 중에 사용된 후보 인덱스 목록

    - key : possible_keys 컬럼에서 보여진 후보 인덱스 목록 중 실제 사용된 인덱스, 인덱스 사용 못했을 경우는 NULL로 표기된다

    - rows : 옵티마이저가 비용산정을 위해 얼마나 많은 레코드를 읽고 비교해야하는지 예측해본 레코드수
             스토리지 엔진별로 쿼리를 처리하기 위해 얼마나 많은 레코드를 디스크로부터 읽고 체크해야하는지를 의미

    - filtered : 스토리지 엔진에서 읽어온 쿼리중에 mysql엔진이 필터링한 비율(통계치라 정확히지않음)

    - extra : MySQL이 어떻게 쿼리를 풀었는지 부가 정보가 나옴
      - using where : where조건으로 데이터를 추출, 대부분 쿼리에서 표시됨, 만약 row칼럼에 데이터와 실제읽어온 데이터의 개수차이가 크다면
                      보완이 필요할 수 있음
      - using filesort : 인덱스를 이용한 정렬을 할 수 없는경우 SortBuffer를 통해서 정렬, 드라이빙 테이블만 정렬할 경우 SortBuffer에서 해결 가능
      - using temporary : 드라이빙테이블만이용해서 정렬을 할 수 없는 경우, 여러 테이블을 조인해서 전부 임시 테이블에 넣어서 정렬하는 방식
      - using index : 커버링 인덱스

  - postgresql
    - index scan은 인덱스를 탐색하는 방식
    - Index only scan은 인덱스에 필요한 모든데이터가 존재하기 떄문에 따로 테이블에 접근할 필요없음 mysql에서 커버링인덱스

  - postgresql vs mysql
      - mysql은 group by에서 group by 칼럼을 기준으로 정렬된 결과를 응답, 내부적으로 정렬이 발생
        정렬하지 않을려면 order by null 구문을 추가해야함
      - mysql에 경우 기본키를 가지고 자동으로 클러스터인덱스가 생성되지만 postgresql는 따로 클러스터인덱스를 만들어 줘야함
  - postgresql,mysql
      - count,exists
        - exists는 exists내부에 결과가 존재할경우 바로 true를 리턴, count는 총 몇건인지 테이블 전부 조회 성능상 같은 결과를 반환할경우
          exists가 성능상 우위

  - 쿼리속도에서 가장 중요한것
      - 인덱스 스캔범위 줄이기, 테이블 엑세스 횟수 줄이기
      - 인덱스 스캔보다 테이블 스캔이 더 빠를 수 있음
      - 인덱스 스캔에서 테이블 엑세스는 랜덤엑세스인 반면, 테이블 스캔에서 테이블엑세스는 시퀀셜 엑세스
      - 인덱스 스캔에서 테이블 엑세스는 Single Block Read, 테이블 스캔에서 테이블 엑세스는 Multi Block Read
      - 옵티마이저가 판단했을때 테이블 스캔 비용이 더 적을경우 인덱스가 있어도 테이블스캔
      - 테이블 스캔을 줄이기 위한 방법 중 커버링 인덱스를 만들수 있으나 너무 많은 컬럼이 있덱스에 있으면 테이블 스캔과 차이가 없을 수 있음
------------------------------------------------------------------------------------------
5. JPA
  - default_batch_fetch_size
    - 연관관계에있는 엔티티를 한꺼번에 읽어올 수 있는 개수를 지정
    - N + 1상황에서 조회된 데이터 개수만큼 연관관계 테이블을 조회하는 쿼리를 전송하기때문에, default_batch_fetch_size를 사용

  - fetchJoin과 일반Join
    - fetchJoin은 N + 1 문제를 해결하기 위해 연관관계에있는 테이블까지 한꺼번에 읽어오는 방법
      - querydsl에서 fetchJoin은 join방식을 규정하지 않음, left join,right join,inner join등 모든 join에서 fetchJoin사용가능
      - spring-data-jpa에서 @EntityGraph의 fetchJoin은 left outer join만 사용함
    - 일반Join은 join쿼리가 발생하지만 select절에서 연관관계테이블의 데이터는 읽어오지 않음, N + 1문제가 발생
    - fetchJoin은 테이블의 모든 컬럼을 읽어오기때문에 상황에 따라 비효율적(안쓰는 컬럼이 응답시간에 영향을 줄 수 있음)
    - dto를 읽어와야한다면 fetchJoin보다 일반join을쓴다음 원하는 칼럼만 반환하는 방식이 효율적

    - fetchJoin에서 on을 사용할 수 없음, fetchJoin은 연관관계에 있는 엔티티가 전부 조회되는 걸 가정
      - on을 사용하여 연관관계에 대상에 조건을 걸면, db상태와 객체의 일관성이 깨질 수 있음
      - 일관성이 깨졋을때 문제는 객체의 상태를 저장한 다면 의도치 안게, db의 데이터가 삭제될 수 있음
      - 이런 이유로 fetchJoin에서 별칭사용을 금지하는데, hibernate에서는 일관성을 꺠지않는 선에서 별칭사용을 허용

    - fetchJoin에서 where은 사용할 수 있지만 상황에 따라 일관성이 깨질 가능성 존재
      - outer join에서 where을 쓴다면 일관성을 보장할 수 없음
        - 패치조인에서 outer join은 왼쪽에 테이블의 모든 row가 보여지는걸 가정함,이 상황에서 where조건을 거는 순간 필터링이 작용하기때문
        - on에서 쓰는 조건과 where에서 쓰는 조건이 다르게 동작하기떄문
        - fetchJoin은 on을 사용못하기때문에 outer join에서 의도와 다른 결과를 반환

      - inner join에서 where을 쓰는건 연관관계에따라 일관성 보장 가능
        - OneToMany에서 대상에 where조건을 쓸 때 연관관계에 있는 엔티티가 전부 조회안될 가능성 존재, 일관성이 깨짐
                      주인에게 where조건은 상관없음 주인은 필터링이 되어도 연관관계에 있는 엔티티는 모두 조회되기때문
        - ManyToOne에서는 대상이나 주인에게 where조건을 걸어도 상관없음 주인과 연관관계에 있는 엔티티는 모두 조회가능

    - fetchJoin에서 where을썻을때 일관성이 보장된다는건 on에서쓴 조건결과와 where필터링 결과가 일치해야함, outer조인은 불가능

    - fetchJoin은 on을 사용할 수 없기때문에 연관관계 주인이나 대상에 조건이 붙은 outerjoin은 구현할 수 없음(쿼리로 작성한것과 결과가 다름)
      - 이를 해결하기 위해서는 fetchJoin이 아닌 일반join을 사용해야함, 일반join사용후 dto를 반환

    - 일관성이 깨지더라도, 2차캐시 없이 조회용으로만 쓰면 문제가 없음, 만약 jpa에서 2차캐시를 쓴다면 똑같은 팀을 조회해도
      먼저 조회한 쿼리에서 대상엔티티에 조건을 걸었다면 같은 엔티티조회라도 다른결과 발생

    - 내부적으로 join하는 쿼리를 전송하기때문에 OneToMany관계의 엔티티를 엔티티목록을 조회한다면 중복이 발생할 수 있음

    - fetchJoin에서 고려해야될점
      - fetchJoin은 연관관계에 있는 엔티티가 모두 조회될거라는 가정을 하고 만들어짐
      - 사용하는 필드 수가 많은지, 적을 수록 비효율적, 안쓰는 특정 필드가 읽어오는데 오래 걸릴 수 있음
      - 일관성 문제, fetchJoin은 on절을 사용 못하기 때문에 쿼리상에서 outer조인,on으로 만들어지는 결과를 fetchJoin으로는 만들 수 없음
        - 이를 모르고 where절을 쓰는 경우가 존재하나 on과 where는 완전 다른 경우
        - 2차 캐시까지 쓴다면, 의도하는 조회결과가 안나올 수 있음
        - innerJoin은 상관없음
      - 연관관계종류, OneToMany의 경우 여러 2개이상의 OneToMany엔티티를 조회하는 경우 나타나는 MultiBagFetchException
        그리고 One쪽 엔티티에 나타나는 데이터중복등을 생각해야함


  - MultipleBagFetchException
    - 원인 : 2개 이상의 OneToMany관계에있는 List타입의 엔티티를 fetchJoin했을때 발생하는 예외
            하이버네이트는 List타입의 OneToMany엔티티에 PersistentBag이라는 인스턴스를 할당에서 데이터를 추가
    - 이유 : OneToMany관계가 있는 엔티티를 fetchJoin결과를 쿼리상에서 확인하면 One쪽테이블만 중복이 발생함
            이때 2개 이상의 OneToMany관계를 포함한 엔티티를  fetchJoin해서 쿼리를 확인하면 Many쪽테이블의 row가 중복발생됨(Team,Member관계에서 Member에 중복이 발생)
            이 중복된 데이터를 엔티티의 리스트가 매핑하지 못하기때문에 예외가 발생
    - 해결 : OneToMany관계의 엔티티를 List가 아닌 Set으로처리하면됨,

  - OneToOne
    - OneToOne관계에서 외래키는 주테이블과 대상테이블 어느곳에서도 존재할 수 있음

    - 외래키가 주테이블에 있는 경우 개발상 편리함
        - 장점 : 주테이블만 조회해도 대상 테이블이 존재하는지 확인가능
        - 단점 : 외래키에 NULL값을 허용하고 변경에 취약함, 만약 회원이 락커를 여러개 가질수 있다면( 1: N관계로 수정) 기존 테이블, 소스코드를 수정해야함
    - 외래키가 대상테이블에 있는 경우 변경에 유연함
        - 장점 : 회원이 락커를 여러개 가지도록 변경되어도(1 : N관계로 수정) 기존 테이블을 수정할 필요 없음, NULL값허용 안함
        - 단점 : 양방향일경우 주테이블에서 지연로딩을 사용할 수 없음음
    - OneToOne양방향에서 연관관계 주인이 아닌경우 지연로딩이 적용안됨
        - 지연로딩은 사용시 엔티티를 영속화시키는 방식으로 그 전에는 필드에 프록시객체가 할당됨
        - null값은 프록시객체를 만들 수 없기때문에 프록시 객체를 만들기위해서는 엔티티에 매핑되는 테이블의 필드값이 null인지 확인을 해야함
        - 연관관계주인이 아닌 엔티티는 연관관계를 맺고있는 엔티티가 null인지여부를 테이블에서 확인할 수 없기때문에 LazyLoading전략이 무시되고한번에 모두 읽어옴
        - OneToMany관계에서는 기본으로 빈 List가 생성되기때문에 null값여부를 확인할 필요 없음

  - DirtyChecking
    - 엔티티를 조회할때 조회시점에 스냅샷을 만들어둠
    - 트랜잭션 끝나는시점에 원본엔티티와 스냅샷를 비교하는 작업이 DirtyChecking, DirtyChecking후에 달라진 부분이 있으면 UPDATE QUERY전송
    - 이때 각 칼럼들을 비교하는데 만약 equals를 오버라이딩하지 않으면 같은 기본적으로 레퍼런스비교를 하기떄문에
      같은 값이라도 신규객체를 생성하면 객체비교시 false가 발생, 이를 위해 equals를 구현해야할 수 도 있음
---------------------------------------------------------------------------------------------------------------------

6. Spring-data-jpa
  - deleteAllById,deleteAllByIdInBatch
    - deleteAllById는 아이디에 해당하는 엔티티들을 조회한후에 아이디 개수만큼 삭제쿼리를 전송
    - deleteAllByIdInBatch는 엔티티 조회없이 하나의 쿼리로 삭제전송
    - deleteAllById는 아이디에 대한 검증이 이뤄지기때문에 아이디에 해당하는 엔티티가 없으면 예외발생
        deleteAllByIdInBatch는 아이디에 대한 검증없이 삭제 쿼리 전송, 아이디에 대한 엔티티가 없어도 예외발생안함

  - existsById,exists
    - existsById는 select count(*) from table where id=? 형식의 쿼리생성
    - exists는 select * from table where id = ? 형식의 쿼리생성
    - 효율화를 위해 native하게 exists쿼리를 생성하는방법이나 querydsl에서 limit구문을 사용할 수 있게 수정
    - count가 들어가는 순간 조건해 해당하는 모든 row를 하나씩 카운팅